2022-06-15 00:23:06,842 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:06,843 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): WordEmbeddings(
      'glove'
      (embedding): Embedding(400001, 100)
    )
    (list_embedding_1): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
    (list_embedding_2): FlairEmbeddings(
      (lm): LanguageModel(
        (drop): Dropout(p=0.05, inplace=False)
        (encoder): Embedding(300, 100)
        (rnn): LSTM(100, 2048)
        (decoder): Linear(in_features=2048, out_features=300, bias=True)
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)
  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=27, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-06-15 00:23:06,843 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:06,843 Corpus: "Corpus: 19077 train + 2120 dev + 4600 test sentences"
2022-06-15 00:23:06,843 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:06,843 Parameters:
2022-06-15 00:23:06,843  - learning_rate: "0.100000"
2022-06-15 00:23:06,843  - mini_batch_size: "32"
2022-06-15 00:23:06,843  - patience: "3"
2022-06-15 00:23:06,843  - anneal_factor: "0.5"
2022-06-15 00:23:06,843  - max_epochs: "10"
2022-06-15 00:23:06,843  - shuffle: "True"
2022-06-15 00:23:06,843  - train_with_dev: "False"
2022-06-15 00:23:06,844  - batch_growth_annealing: "False"
2022-06-15 00:23:06,844 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:06,844 Model training base path: "res/part3/flair/log"
2022-06-15 00:23:06,844 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:06,844 Device: cuda:0
2022-06-15 00:23:06,844 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:06,844 Embeddings storage mode: cpu
2022-06-15 00:23:06,844 ----------------------------------------------------------------------------------------------------
2022-06-15 00:23:16,685 epoch 1 - iter 59/597 - loss 0.90580037 - samples/sec: 191.93 - lr: 0.100000
2022-06-15 00:23:26,871 epoch 1 - iter 118/597 - loss 0.64378218 - samples/sec: 185.44 - lr: 0.100000
2022-06-15 00:23:37,335 epoch 1 - iter 177/597 - loss 0.52211300 - samples/sec: 180.51 - lr: 0.100000
2022-06-15 00:23:47,165 epoch 1 - iter 236/597 - loss 0.44890717 - samples/sec: 192.15 - lr: 0.100000
2022-06-15 00:23:57,092 epoch 1 - iter 295/597 - loss 0.39294373 - samples/sec: 190.28 - lr: 0.100000
2022-06-15 00:24:07,054 epoch 1 - iter 354/597 - loss 0.35220749 - samples/sec: 189.60 - lr: 0.100000
2022-06-15 00:24:17,205 epoch 1 - iter 413/597 - loss 0.32466948 - samples/sec: 186.07 - lr: 0.100000
2022-06-15 00:24:28,408 epoch 1 - iter 472/597 - loss 0.30225888 - samples/sec: 168.60 - lr: 0.100000
2022-06-15 00:24:39,777 epoch 1 - iter 531/597 - loss 0.28180785 - samples/sec: 166.14 - lr: 0.100000
2022-06-15 00:24:50,423 epoch 1 - iter 590/597 - loss 0.26498159 - samples/sec: 177.42 - lr: 0.100000
2022-06-15 00:24:51,531 ----------------------------------------------------------------------------------------------------
2022-06-15 00:24:51,531 EPOCH 1 done: loss 0.2634 - lr 0.100000
2022-06-15 00:25:33,864 Evaluating as a multi-label problem: False
2022-06-15 00:25:47,276 Evaluating as a multi-label problem: False
2022-06-15 00:25:47,301 DEV : loss 0.08801651000976562 - f1-score (micro avg)  0.8893
2022-06-15 00:25:47,402 BAD EPOCHS (no improvement): 0
2022-06-15 00:25:47,403 saving best model
2022-06-15 00:25:49,462 ----------------------------------------------------------------------------------------------------
2022-06-15 00:25:53,027 epoch 2 - iter 59/597 - loss 0.10724448 - samples/sec: 530.77 - lr: 0.100000
2022-06-15 00:25:56,468 epoch 2 - iter 118/597 - loss 0.10534119 - samples/sec: 549.50 - lr: 0.100000
2022-06-15 00:25:59,852 epoch 2 - iter 177/597 - loss 0.10398580 - samples/sec: 558.64 - lr: 0.100000
2022-06-15 00:26:03,246 epoch 2 - iter 236/597 - loss 0.10100313 - samples/sec: 557.14 - lr: 0.100000
2022-06-15 00:26:06,615 epoch 2 - iter 295/597 - loss 0.09913034 - samples/sec: 561.06 - lr: 0.100000
2022-06-15 00:26:09,906 epoch 2 - iter 354/597 - loss 0.09872669 - samples/sec: 574.63 - lr: 0.100000
2022-06-15 00:26:13,287 epoch 2 - iter 413/597 - loss 0.09709972 - samples/sec: 559.11 - lr: 0.100000
2022-06-15 00:26:16,699 epoch 2 - iter 472/597 - loss 0.09636430 - samples/sec: 554.13 - lr: 0.100000
2022-06-15 00:26:20,060 epoch 2 - iter 531/597 - loss 0.09590039 - samples/sec: 562.57 - lr: 0.100000
2022-06-15 00:26:23,397 epoch 2 - iter 590/597 - loss 0.09408579 - samples/sec: 566.56 - lr: 0.100000
2022-06-15 00:26:23,786 ----------------------------------------------------------------------------------------------------
2022-06-15 00:26:23,786 EPOCH 2 done: loss 0.0942 - lr 0.100000
2022-06-15 00:27:06,668 Evaluating as a multi-label problem: False
2022-06-15 00:27:12,678 Evaluating as a multi-label problem: False
2022-06-15 00:27:12,703 DEV : loss 0.0552859865128994 - f1-score (micro avg)  0.9244
2022-06-15 00:27:12,821 BAD EPOCHS (no improvement): 0
2022-06-15 00:27:12,821 saving best model
2022-06-15 00:27:14,789 ----------------------------------------------------------------------------------------------------
2022-06-15 00:27:18,371 epoch 3 - iter 59/597 - loss 0.07403146 - samples/sec: 528.12 - lr: 0.100000
2022-06-15 00:27:21,691 epoch 3 - iter 118/597 - loss 0.07348843 - samples/sec: 569.53 - lr: 0.100000
2022-06-15 00:27:25,084 epoch 3 - iter 177/597 - loss 0.07539036 - samples/sec: 557.21 - lr: 0.100000
2022-06-15 00:27:28,482 epoch 3 - iter 236/597 - loss 0.07592665 - samples/sec: 556.49 - lr: 0.100000
2022-06-15 00:27:32,014 epoch 3 - iter 295/597 - loss 0.07506696 - samples/sec: 535.24 - lr: 0.100000
2022-06-15 00:27:35,385 epoch 3 - iter 354/597 - loss 0.07336981 - samples/sec: 560.83 - lr: 0.100000
2022-06-15 00:27:39,463 epoch 3 - iter 413/597 - loss 0.07256576 - samples/sec: 463.65 - lr: 0.100000
2022-06-15 00:27:42,899 epoch 3 - iter 472/597 - loss 0.07231094 - samples/sec: 550.29 - lr: 0.100000
2022-06-15 00:27:46,218 epoch 3 - iter 531/597 - loss 0.07263696 - samples/sec: 569.65 - lr: 0.100000
2022-06-15 00:27:49,633 epoch 3 - iter 590/597 - loss 0.07170426 - samples/sec: 553.54 - lr: 0.100000
2022-06-15 00:27:49,966 ----------------------------------------------------------------------------------------------------
2022-06-15 00:27:49,967 EPOCH 3 done: loss 0.0717 - lr 0.100000
2022-06-15 00:28:33,227 Evaluating as a multi-label problem: False
2022-06-15 00:28:40,366 Evaluating as a multi-label problem: False
2022-06-15 00:28:40,391 DEV : loss 0.04551102593541145 - f1-score (micro avg)  0.9383
2022-06-15 00:28:40,503 BAD EPOCHS (no improvement): 0
2022-06-15 00:28:40,504 saving best model
2022-06-15 00:28:42,517 ----------------------------------------------------------------------------------------------------
2022-06-15 00:28:46,061 epoch 4 - iter 59/597 - loss 0.05936555 - samples/sec: 533.79 - lr: 0.100000
2022-06-15 00:28:49,481 epoch 4 - iter 118/597 - loss 0.05883232 - samples/sec: 552.79 - lr: 0.100000
2022-06-15 00:28:52,997 epoch 4 - iter 177/597 - loss 0.05990352 - samples/sec: 537.68 - lr: 0.100000
2022-06-15 00:28:56,377 epoch 4 - iter 236/597 - loss 0.06013004 - samples/sec: 559.41 - lr: 0.100000
2022-06-15 00:28:59,775 epoch 4 - iter 295/597 - loss 0.05930745 - samples/sec: 556.39 - lr: 0.100000
2022-06-15 00:29:03,208 epoch 4 - iter 354/597 - loss 0.05908821 - samples/sec: 550.65 - lr: 0.100000
2022-06-15 00:29:06,668 epoch 4 - iter 413/597 - loss 0.05954150 - samples/sec: 546.44 - lr: 0.100000
2022-06-15 00:29:10,148 epoch 4 - iter 472/597 - loss 0.05967573 - samples/sec: 543.38 - lr: 0.100000
2022-06-15 00:29:13,545 epoch 4 - iter 531/597 - loss 0.06023902 - samples/sec: 556.57 - lr: 0.100000
2022-06-15 00:29:16,838 epoch 4 - iter 590/597 - loss 0.06027342 - samples/sec: 574.20 - lr: 0.100000
2022-06-15 00:29:17,182 ----------------------------------------------------------------------------------------------------
2022-06-15 00:29:17,183 EPOCH 4 done: loss 0.0604 - lr 0.100000
2022-06-15 00:30:00,092 Evaluating as a multi-label problem: False
2022-06-15 00:30:06,452 Evaluating as a multi-label problem: False
2022-06-15 00:30:06,478 DEV : loss 0.04117140918970108 - f1-score (micro avg)  0.9432
2022-06-15 00:30:06,599 BAD EPOCHS (no improvement): 0
2022-06-15 00:30:06,600 saving best model
2022-06-15 00:30:08,629 ----------------------------------------------------------------------------------------------------
2022-06-15 00:30:12,335 epoch 5 - iter 59/597 - loss 0.06122172 - samples/sec: 510.43 - lr: 0.100000
2022-06-15 00:30:15,861 epoch 5 - iter 118/597 - loss 0.05812772 - samples/sec: 536.15 - lr: 0.100000
2022-06-15 00:30:19,256 epoch 5 - iter 177/597 - loss 0.05768733 - samples/sec: 556.99 - lr: 0.100000
2022-06-15 00:30:22,700 epoch 5 - iter 236/597 - loss 0.05758680 - samples/sec: 549.09 - lr: 0.100000
2022-06-15 00:30:26,415 epoch 5 - iter 295/597 - loss 0.05691103 - samples/sec: 508.90 - lr: 0.100000
2022-06-15 00:30:30,112 epoch 5 - iter 354/597 - loss 0.05552620 - samples/sec: 511.39 - lr: 0.100000
2022-06-15 00:30:33,700 epoch 5 - iter 413/597 - loss 0.05495698 - samples/sec: 527.06 - lr: 0.100000
2022-06-15 00:30:37,266 epoch 5 - iter 472/597 - loss 0.05469613 - samples/sec: 530.21 - lr: 0.100000
2022-06-15 00:30:41,268 epoch 5 - iter 531/597 - loss 0.05449847 - samples/sec: 472.43 - lr: 0.100000
2022-06-15 00:30:45,012 epoch 5 - iter 590/597 - loss 0.05435922 - samples/sec: 505.05 - lr: 0.100000
2022-06-15 00:30:45,400 ----------------------------------------------------------------------------------------------------
2022-06-15 00:30:45,401 EPOCH 5 done: loss 0.0543 - lr 0.100000
2022-06-15 00:31:30,687 Evaluating as a multi-label problem: False
2022-06-15 00:31:37,154 Evaluating as a multi-label problem: False
2022-06-15 00:31:37,179 DEV : loss 0.03721347451210022 - f1-score (micro avg)  0.9459
2022-06-15 00:31:37,300 BAD EPOCHS (no improvement): 0
2022-06-15 00:31:37,301 saving best model
2022-06-15 00:31:39,318 ----------------------------------------------------------------------------------------------------
2022-06-15 00:31:43,091 epoch 6 - iter 59/597 - loss 0.04711781 - samples/sec: 501.39 - lr: 0.100000
2022-06-15 00:31:46,627 epoch 6 - iter 118/597 - loss 0.04585201 - samples/sec: 534.66 - lr: 0.100000
2022-06-15 00:31:50,231 epoch 6 - iter 177/597 - loss 0.04742646 - samples/sec: 524.66 - lr: 0.100000
2022-06-15 00:31:53,955 epoch 6 - iter 236/597 - loss 0.05136939 - samples/sec: 507.69 - lr: 0.100000
2022-06-15 00:31:57,539 epoch 6 - iter 295/597 - loss 0.05191444 - samples/sec: 527.58 - lr: 0.100000
2022-06-15 00:32:01,107 epoch 6 - iter 354/597 - loss 0.05187975 - samples/sec: 529.84 - lr: 0.100000
2022-06-15 00:32:04,664 epoch 6 - iter 413/597 - loss 0.05158284 - samples/sec: 531.67 - lr: 0.100000
2022-06-15 00:32:08,229 epoch 6 - iter 472/597 - loss 0.05103543 - samples/sec: 530.40 - lr: 0.100000
2022-06-15 00:32:11,821 epoch 6 - iter 531/597 - loss 0.05027900 - samples/sec: 526.24 - lr: 0.100000
2022-06-15 00:32:15,531 epoch 6 - iter 590/597 - loss 0.04994138 - samples/sec: 509.73 - lr: 0.100000
2022-06-15 00:32:15,921 ----------------------------------------------------------------------------------------------------
2022-06-15 00:32:15,921 EPOCH 6 done: loss 0.0499 - lr 0.100000
2022-06-15 00:33:01,724 Evaluating as a multi-label problem: False
2022-06-15 00:33:07,816 Evaluating as a multi-label problem: False
2022-06-15 00:33:07,841 DEV : loss 0.036527540534734726 - f1-score (micro avg)  0.9576
2022-06-15 00:33:07,955 BAD EPOCHS (no improvement): 0
2022-06-15 00:33:07,955 saving best model
2022-06-15 00:33:09,972 ----------------------------------------------------------------------------------------------------
2022-06-15 00:33:13,561 epoch 7 - iter 59/597 - loss 0.04117178 - samples/sec: 527.02 - lr: 0.100000
2022-06-15 00:33:16,998 epoch 7 - iter 118/597 - loss 0.04452490 - samples/sec: 549.94 - lr: 0.100000
2022-06-15 00:33:20,470 epoch 7 - iter 177/597 - loss 0.04495588 - samples/sec: 544.56 - lr: 0.100000
2022-06-15 00:33:23,861 epoch 7 - iter 236/597 - loss 0.04454884 - samples/sec: 557.40 - lr: 0.100000
2022-06-15 00:33:27,211 epoch 7 - iter 295/597 - loss 0.04456559 - samples/sec: 564.43 - lr: 0.100000
2022-06-15 00:33:30,653 epoch 7 - iter 354/597 - loss 0.04455423 - samples/sec: 549.23 - lr: 0.100000
2022-06-15 00:33:34,063 epoch 7 - iter 413/597 - loss 0.04457399 - samples/sec: 554.41 - lr: 0.100000
2022-06-15 00:33:37,435 epoch 7 - iter 472/597 - loss 0.04513981 - samples/sec: 560.60 - lr: 0.100000
2022-06-15 00:33:40,785 epoch 7 - iter 531/597 - loss 0.04486701 - samples/sec: 564.44 - lr: 0.100000
2022-06-15 00:33:44,191 epoch 7 - iter 590/597 - loss 0.04539531 - samples/sec: 555.10 - lr: 0.100000
2022-06-15 00:33:44,644 ----------------------------------------------------------------------------------------------------
2022-06-15 00:33:44,645 EPOCH 7 done: loss 0.0455 - lr 0.100000
2022-06-15 00:34:27,835 Evaluating as a multi-label problem: False
2022-06-15 00:34:34,895 Evaluating as a multi-label problem: False
2022-06-15 00:34:34,920 DEV : loss 0.032530028373003006 - f1-score (micro avg)  0.9583
2022-06-15 00:34:35,031 BAD EPOCHS (no improvement): 0
2022-06-15 00:34:35,031 saving best model
2022-06-15 00:34:37,036 ----------------------------------------------------------------------------------------------------
2022-06-15 00:34:40,678 epoch 8 - iter 59/597 - loss 0.03959271 - samples/sec: 519.36 - lr: 0.100000
2022-06-15 00:34:44,458 epoch 8 - iter 118/597 - loss 0.03979473 - samples/sec: 500.23 - lr: 0.100000
2022-06-15 00:34:48,108 epoch 8 - iter 177/597 - loss 0.03957835 - samples/sec: 518.05 - lr: 0.100000
2022-06-15 00:34:51,723 epoch 8 - iter 236/597 - loss 0.04041372 - samples/sec: 523.06 - lr: 0.100000
2022-06-15 00:34:55,233 epoch 8 - iter 295/597 - loss 0.03979470 - samples/sec: 538.60 - lr: 0.100000
2022-06-15 00:34:58,785 epoch 8 - iter 354/597 - loss 0.03983740 - samples/sec: 532.49 - lr: 0.100000
2022-06-15 00:35:02,452 epoch 8 - iter 413/597 - loss 0.04019531 - samples/sec: 515.49 - lr: 0.100000
2022-06-15 00:35:06,167 epoch 8 - iter 472/597 - loss 0.04094984 - samples/sec: 508.95 - lr: 0.100000
2022-06-15 00:35:09,784 epoch 8 - iter 531/597 - loss 0.04125954 - samples/sec: 522.87 - lr: 0.100000
2022-06-15 00:35:13,414 epoch 8 - iter 590/597 - loss 0.04147831 - samples/sec: 520.84 - lr: 0.100000
2022-06-15 00:35:13,796 ----------------------------------------------------------------------------------------------------
2022-06-15 00:35:13,796 EPOCH 8 done: loss 0.0413 - lr 0.100000
2022-06-15 00:35:59,192 Evaluating as a multi-label problem: False
2022-06-15 00:36:05,681 Evaluating as a multi-label problem: False
2022-06-15 00:36:05,707 DEV : loss 0.03329326584935188 - f1-score (micro avg)  0.9553
2022-06-15 00:36:05,827 BAD EPOCHS (no improvement): 1
2022-06-15 00:36:05,828 ----------------------------------------------------------------------------------------------------
2022-06-15 00:36:09,537 epoch 9 - iter 59/597 - loss 0.03830798 - samples/sec: 509.91 - lr: 0.100000
2022-06-15 00:36:13,221 epoch 9 - iter 118/597 - loss 0.03800994 - samples/sec: 513.21 - lr: 0.100000
2022-06-15 00:36:16,888 epoch 9 - iter 177/597 - loss 0.03817268 - samples/sec: 515.58 - lr: 0.100000
2022-06-15 00:36:20,438 epoch 9 - iter 236/597 - loss 0.03889024 - samples/sec: 532.72 - lr: 0.100000
2022-06-15 00:36:24,071 epoch 9 - iter 295/597 - loss 0.03844102 - samples/sec: 520.39 - lr: 0.100000
2022-06-15 00:36:27,560 epoch 9 - iter 354/597 - loss 0.03859112 - samples/sec: 541.99 - lr: 0.100000
2022-06-15 00:36:31,278 epoch 9 - iter 413/597 - loss 0.03904420 - samples/sec: 508.46 - lr: 0.100000
2022-06-15 00:36:35,882 epoch 9 - iter 472/597 - loss 0.03906599 - samples/sec: 410.56 - lr: 0.100000
2022-06-15 00:36:39,581 epoch 9 - iter 531/597 - loss 0.03911119 - samples/sec: 511.20 - lr: 0.100000
2022-06-15 00:36:43,258 epoch 9 - iter 590/597 - loss 0.03882947 - samples/sec: 514.16 - lr: 0.100000
2022-06-15 00:36:43,664 ----------------------------------------------------------------------------------------------------
2022-06-15 00:36:43,664 EPOCH 9 done: loss 0.0388 - lr 0.100000
2022-06-15 00:37:29,401 Evaluating as a multi-label problem: False
2022-06-15 00:37:35,828 Evaluating as a multi-label problem: False
2022-06-15 00:37:35,855 DEV : loss 0.03175075352191925 - f1-score (micro avg)  0.9572
2022-06-15 00:37:35,967 BAD EPOCHS (no improvement): 2
2022-06-15 00:37:35,967 ----------------------------------------------------------------------------------------------------
2022-06-15 00:37:39,677 epoch 10 - iter 59/597 - loss 0.03521925 - samples/sec: 509.80 - lr: 0.100000
2022-06-15 00:37:43,195 epoch 10 - iter 118/597 - loss 0.03567873 - samples/sec: 537.47 - lr: 0.100000
2022-06-15 00:37:46,826 epoch 10 - iter 177/597 - loss 0.03545195 - samples/sec: 520.77 - lr: 0.100000
2022-06-15 00:37:50,455 epoch 10 - iter 236/597 - loss 0.03472874 - samples/sec: 521.02 - lr: 0.100000
2022-06-15 00:37:54,088 epoch 10 - iter 295/597 - loss 0.03508030 - samples/sec: 520.42 - lr: 0.100000
2022-06-15 00:37:57,622 epoch 10 - iter 354/597 - loss 0.03593379 - samples/sec: 535.14 - lr: 0.100000
2022-06-15 00:38:01,201 epoch 10 - iter 413/597 - loss 0.03639941 - samples/sec: 528.23 - lr: 0.100000
2022-06-15 00:38:04,794 epoch 10 - iter 472/597 - loss 0.03662348 - samples/sec: 526.24 - lr: 0.100000
2022-06-15 00:38:08,419 epoch 10 - iter 531/597 - loss 0.03676179 - samples/sec: 521.67 - lr: 0.100000
2022-06-15 00:38:12,082 epoch 10 - iter 590/597 - loss 0.03662497 - samples/sec: 516.13 - lr: 0.100000
2022-06-15 00:38:12,458 ----------------------------------------------------------------------------------------------------
2022-06-15 00:38:12,458 EPOCH 10 done: loss 0.0367 - lr 0.100000
2022-06-15 00:38:57,499 Evaluating as a multi-label problem: False
2022-06-15 00:39:03,469 Evaluating as a multi-label problem: False
2022-06-15 00:39:03,494 DEV : loss 0.02740071341395378 - f1-score (micro avg)  0.9613
2022-06-15 00:39:03,603 BAD EPOCHS (no improvement): 0
2022-06-15 00:39:03,604 saving best model
2022-06-15 00:39:05,557 ----------------------------------------------------------------------------------------------------
2022-06-15 00:39:05,557 loading file res/part3/flair/log/best-model.pt
2022-06-15 00:39:06,676 SequenceTagger predicts: Dictionary with 27 tags: O, S-city, B-city, E-city, I-city, S-time, B-time, E-time, I-time, S-date, B-date, E-date, I-date, S-people, B-people, E-people, I-people, S-first_name, B-first_name, E-first_name, I-first_name, S-last_name, B-last_name, E-last_name, I-last_name, <START>, <STOP>
2022-06-15 00:39:27,647 Evaluating as a multi-label problem: False
2022-06-15 00:39:27,698 0.9497	0.9541	0.9519	0.9202
2022-06-15 00:39:27,698 
Results:
- F-score (micro) 0.9519
- F-score (macro) 0.9495
- Accuracy 0.9202

By class:
              precision    recall  f1-score   support

        city     0.9940    0.9946    0.9943      1495
        time     0.9434    0.9365    0.9399      1086
        date     0.9398    0.9424    0.9411      1077
      people     0.8961    0.9219    0.9088       973
   last_name     0.9382    0.9693    0.9535       423
  first_name     0.9749    0.9440    0.9592       411

   micro avg     0.9497    0.9541    0.9519      5465
   macro avg     0.9477    0.9515    0.9495      5465
weighted avg     0.9501    0.9541    0.9520      5465

2022-06-15 00:39:27,699 ----------------------------------------------------------------------------------------------------
